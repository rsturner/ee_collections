# Import necessary libraries.
import geopandas as gpd  # For geospatial data manipulation
import pandas as pd  # For data manipulation
import json 
import ee  # Google Earth Engine API
import wxee  # Extension for Google Earth Engine
from shapely.geometry import Point  
import numpy as np 
from datetime import datetime  # For working with dates

# Authenticate and initialise Earth Engine API.
ee.Authenticate()
ee.Initialize()

# Apply scaling factors.
def applyScaleFactors_S2(image):
  optical_bands = image.select('B.*').multiply(0.0001)
  return image.addBands(optical_bands, None, True) \
              .select(['B4', 'B8', 'SCL'], ['RED', 'NIR', 'SCL'])

# NDVI function.
def addNDVI_S2(image):
    ndvi = image.normalizedDifference(['NIR', 'RED']).rename('NDVI')
    return image.addBands(ndvi)

# Read in shapefile to define the region of interest (roi).
shapefile = gpd.read_file('~/path_to_shapefile/isle_of_rum.shp')
js = json.loads(shapefile.to_json())
roi = ee.Geometry(ee.FeatureCollection(js).geometry())

# Convert float64 values to float32.
def convertToFloat32(image):
    return image.toFloat()

# Import the Sentinel-2b collection, by each year to make batches more manageable for processing.
s2b_2017 = (ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED").filterDate('2017-03-28', '2017-12-31')
                                                             .filterBounds(roi)
                                                             .map(applyScaleFactors_S2)
                                                             .map(addNDVI_S2)
                                                             .filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2B'))
                                                             .map(convertToFloat32))

s2b_2018 = (ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED").filterDate('2018-01-01', '2018-12-31')
                                                             .filterBounds(roi)
                                                             .map(applyScaleFactors_S2)
                                                             .map(addNDVI_S2)
                                                             .filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2B'))
                                                             .map(convertToFloat32))

s2b_2019 = (ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED").filterDate('2019-01-01', '2019-12-31')
                                                             .filterBounds(roi)
                                                             .map(applyScaleFactors_S2)
                                                             .map(addNDVI_S2)
                                                             .filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2B'))
                                                             .map(convertToFloat32))

s2b_2020 = (ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED").filterDate('2020-01-01', '2020-12-31')
                                                             .filterBounds(roi)
                                                             .map(applyScaleFactors_S2)
                                                             .map(addNDVI_S2)
                                                             .filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2B'))
                                                             .map(convertToFloat32))

s2b_2021 = (ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED").filterDate('2021-01-01', '2021-12-31')
                                                             .filterBounds(roi)
                                                             .map(applyScaleFactors_S2)
                                                             .map(addNDVI_S2)
                                                             .filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2B'))
                                                             .map(convertToFloat32))

s2b_2022 = (ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED").filterDate('2022-01-01', '2022-12-31')
                                                             .filterBounds(roi)
                                                             .map(applyScaleFactors_S2)
                                                             .map(addNDVI_S2)
                                                             .filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2B'))
                                                             .map(convertToFloat32))

s2b_2023 = (ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED").filterDate('2023-01-01', '2023-12-08')
                                                             .filterBounds(roi)
                                                             .map(applyScaleFactors_S2)
                                                             .map(addNDVI_S2)
                                                             .filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2B'))
                                                             .map(convertToFloat32))

# Function to extract image metadata.
def extract_metadata_to_df(image_collection):
    # Get information from the ImageCollection
    metadata = image_collection.getInfo()

    # Extract properties
    features = metadata['features']
    properties_list = []
    for feature in features:
        properties_list.append(feature['properties'])

    # Convert to pandas DataFrame
    df = pd.DataFrame(properties_list)

   # Rename index to 'IMAGE_ID' and make it a column
    df = df.reset_index().rename(columns={'index': 'IMAGE_ID'})
    df['IMAGE_ID'] = df.IMAGE_ID + 1

    # Select specific columns (optional)
    required_columns = ['IMAGE_ID', 'SPACECRAFT_NAME']
    for col in required_columns:
        if col not in df.columns:
            df[col] = float('nan')

    # Reorder columns
    df = df[required_columns]

    return df

# Extract image metadata.
s2b_2017_metadata = extract_metadata_to_df(s2b_2017)
s2b_2018_metadata = extract_metadata_to_df(s2b_2018)
s2b_2019_metadata = extract_metadata_to_df(s2b_2019)
s2b_2020_metadata = extract_metadata_to_df(s2b_2020)
s2b_2021_metadata = extract_metadata_to_df(s2b_2021)
s2b_2022_metadata = extract_metadata_to_df(s2b_2022)
s2b_2023_metadata = extract_metadata_to_df(s2b_2023)

# Transform image collections to xarray.
scale = 10
crs = 'EPSG:4326'
s2b_2017_ds = s2b_2017.wx.to_xarray(scale = scale, crs=crs, region = roi)
s2b_2018_ds = s2b_2018.wx.to_xarray(scale = scale, crs=crs, region = roi)
s2b_2019_ds = s2b_2019.wx.to_xarray(scale = scale, crs=crs, region = roi)
s2b_2020_ds = s2b_2020.wx.to_xarray(scale = scale, crs=crs, region = roi)
s2b_2021_ds = s2b_2021.wx.to_xarray(scale = scale, crs=crs, region = roi)
s2b_2022_ds = s2b_2022.wx.to_xarray(scale = scale, crs=crs, region = roi)
s2b_2023_ds = s2b_2023.wx.to_xarray(scale = scale, crs=crs, region = roi)

# Clip xarray to retain only data within the shapefile boundaries.
def clip_to_shp(xarr, shapefile):
    df = xarr.to_dataframe().reset_index()

    # Renaming columns and dropping 'spatial_ref' column
    df.rename(columns={'time': 'TIME', 'x': 'X', 'y': 'Y'}, inplace=True)
    df.drop(columns='spatial_ref', errors='ignore', inplace=True)

    # Creating a GeoDataFrame from the DataFrame
    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['X'], df['Y']), crs='EPSG:4326')

    # Clipping the GeoDataFrame using the shapefile
    gdf = gpd.clip(gdf, shapefile)

    df_clipped = gdf.drop(columns='geometry')

    # Grouping by 'TIME' and creating 'IMAGE ID'
    df_clipped['IMAGE_ID'] = df_clipped.groupby('TIME').ngroup() + 1

    # Reorder rows based on 'IMAGE_ID', 'TIME', 'X', and 'Y' columns
    df_clipped = df_clipped.sort_values(['IMAGE_ID', 'TIME', 'X', 'Y'])

    return df_clipped

s2b_2017_clipped = clip_to_shp(s2b_2017_ds, shapefile)
s2b_2018_clipped = clip_to_shp(s2b_2018_ds, shapefile)
s2b_2019_clipped = clip_to_shp(s2b_2019_ds, shapefile)
s2b_2020_clipped = clip_to_shp(s2b_2020_ds, shapefile)
s2b_2021_clipped = clip_to_shp(s2b_2021_ds, shapefile)
s2b_2022_clipped = clip_to_shp(s2b_2022_ds, shapefile)
s2b_2023_clipped = clip_to_shp(s2b_2023_ds, shapefile)

# Join clipped and metadata dataframes by 'IMAGE_ID'.
s2b_2017_df = s2b_2017_clipped.merge(s2b_2017_metadata, on='IMAGE_ID')
s2b_2018_df = s2b_2018_clipped.merge(s2b_2018_metadata, on='IMAGE_ID')
s2b_2019_df = s2b_2019_clipped.merge(s2b_2019_metadata, on='IMAGE_ID')
s2b_2020_df = s2b_2020_clipped.merge(s2b_2020_metadata, on='IMAGE_ID')
s2b_2021_df = s2b_2021_clipped.merge(s2b_2021_metadata, on='IMAGE_ID')
s2b_2022_df = s2b_2022_clipped.merge(s2b_2022_metadata, on='IMAGE_ID')
s2b_2023_df = s2b_2023_clipped.merge(s2b_2023_metadata, on='IMAGE_ID')

# Drop the 'IMAGE_ID' column as it is no longer needed.
s2b_2017_df.drop(columns='IMAGE_ID', inplace=True)
s2b_2018_df.drop(columns='IMAGE_ID', inplace=True)
s2b_2019_df.drop(columns='IMAGE_ID', inplace=True)
s2b_2020_df.drop(columns='IMAGE_ID', inplace=True)
s2b_2021_df.drop(columns='IMAGE_ID', inplace=True)
s2b_2022_df.drop(columns='IMAGE_ID', inplace=True)
s2b_2023_df.drop(columns='IMAGE_ID', inplace=True)

# Convert columns to strings.
s2b_2017_df = s2b_2017_df.astype(str)
s2b_2018_df = s2b_2018_df.astype(str)
s2b_2019_df = s2b_2019_df.astype(str)
s2b_2020_df = s2b_2020_df.astype(str)
s2b_2021_df = s2b_2021_df.astype(str)
s2b_2022_df = s2b_2022_df.astype(str)
s2b_2023_df = s2b_2023_df.astype(str)

# Apply strip() and lower() to columns.
s2b_2017_df = s2b_2017_df.apply(lambda x: x.str.strip().str.lower())
s2b_2018_df = s2b_2018_df.apply(lambda x: x.str.strip().str.lower())
s2b_2019_df = s2b_2019_df.apply(lambda x: x.str.strip().str.lower())
s2b_2020_df = s2b_2020_df.apply(lambda x: x.str.strip().str.lower())
s2b_2021_df = s2b_2021_df.apply(lambda x: x.str.strip().str.lower())
s2b_2022_df = s2b_2022_df.apply(lambda x: x.str.strip().str.lower())
s2b_2023_df = s2b_2023_df.apply(lambda x: x.str.strip().str.lower())

# Combine to a single dataframe.
s2b_collection = pd.concat([s2b_2017_df, s2b_2018_df, s2b_2019_df,
                            s2b_2020_df, s2b_2021_df, s2b_2022_df,
                            s2b_2023_df], axis=0)

# Replace 'nan' with 'NA'.
s2b_collection = s2b_collection.replace('nan', 'NA')

# Function to split the 'TIME' column into 'DATE' and 'TIME' then reorder columns to ensure they come first.
def datetime(df):
    # Convert 'TIME' column to datetime
    df['TIME'] = pd.to_datetime(df['TIME'])

    # Extracting date and time components
    df['DATE'] = df['TIME'].dt.date
    df['TIME'] = df['TIME'].dt.time

    # Reorder columns
    cols = list(df.columns)
    cols.remove('DATE')
    cols.remove('TIME')
    df = df[['DATE', 'TIME'] + cols]

    # Convert all column names to lowercase
    df.columns = map(str.lower, df.columns)

    return df

s2b_collection = datetime(s2b_collection)

# Function to transform projection to British National Grid EPSG:27700.
def convert_coordinates(df, input_crs='EPSG:4326', output_crs='EPSG:27700'):
    # Create a GeoDataFrame
    geometry = [Point(xy) for xy in zip(df['x'], df['y'])]
    gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=input_crs)

    # Transform coordinates
    gdf = gdf.to_crs(output_crs)

    # Extract easting and northing coordinates
    gdf['easting'] = gdf['geometry'].x
    gdf['northing'] = gdf['geometry'].y

    # Drop the geometry column if needed
    df_transformed = gdf.drop(columns='geometry')

    return df_transformed

s2b_collection = convert_coordinates(s2b_collection)

# Rename columns to match syntax in Landsat collection.
s2b_collection = s2b_collection.rename(columns={'scl': 'pqa', 'spacecraft_name': 'spacecraft_id'})

# Select specific columns.
selected_columns = ['date', 'time', 'northing', 'easting', 'nir', 'red', 'ndvi', 'pqa', 'spacecraft_id']
s2b_collection = s2b_collection[selected_columns]

# Create columns for month, season, and date.
def process_dates(df):
    df['date'] = pd.to_datetime(df['date'])
    df['month'] = df['date'].dt.month
    df['year'] = df['date'].dt.year
    df['month_as_date'] = pd.to_datetime(df.apply(lambda row: f"{row['year']}-{row['month']:02d}-01", axis=1))
    df['year_as_date'] = pd.to_datetime(df['year'].apply(lambda year: f"{year}-01-01"))
    return df

s2b_collection = process_dates(s2b_collection)

def calculate_season_date(row):
    if 3 <= row['month'] <= 5:
        return pd.to_datetime(f"{row['year']}-03-01")
    elif 6 <= row['month'] <= 8:
        return pd.to_datetime(f"{row['year']}-06-01")
    elif 9 <= row['month'] <= 11:
        return pd.to_datetime(f"{row['year']}-09-01")
    elif row['month'] == 12:
        return pd.to_datetime(f"{row['year']}-12-01")
    else:
        return pd.to_datetime(f"{row['year'] - 1}-12-01")

def add_season_as_date_column(df):
    df['season_as_date'] = df.apply(calculate_season_date, axis=1)
    return df

s2b_collection = add_season_as_date_column(s2b_collection)

# Mutate pqa column to match definitions of Landsat pixels.
s2b_collection['pqa'] = np.select(
    [s2b_collection['pqa'].isin([1, 2, 5]),
     s2b_collection['pqa'].isin([7, 8, 9, 10]),
     s2b_collection['pqa'] == 3,
     s2b_collection['pqa'] == 11,
     s2b_collection['pqa'] == 4,
     s2b_collection['pqa'] == 6],
    ['non-valid', 'cloud', 'cloud_shadow', 'snow', 'valid', 'water'],
    default=np.nan)

# Convert all character columns to lowercase.
s2b_collection = s2b_collection.apply(lambda x: x.astype(str).str.lower() if x.dtype == 'O' else x)

# Filter duplicates, keeping the first instance.
s2b_collection = s2b_collection.drop_duplicates()

# Mutate unique image_id column.
s2b_collection['image_id'] = (s2b_collection['date'].astype(str) + '_' +
                              s2b_collection['time'].astype(str) + '_' +
                              s2b_collection['spacecraft_id'].astype(str))

# Select specific columns.
selected_columns = ['date', 'month_as_date', 'season_as_date', 'year_as_date',
                    'image_id', 'northing', 'easting', 'ndvi', 'pqa', 'spacecraft_id']
s2b_collection = s2b_collection[selected_columns]

# Export to csv
s2b_collection = s2b_collection.to_csv("rum_sentinel_2b.csv")
